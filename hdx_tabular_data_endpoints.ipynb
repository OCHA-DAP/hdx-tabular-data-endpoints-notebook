{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c39cd7",
   "metadata": {
    "id": "f7c39cd7"
   },
   "source": [
    "\n",
    "# HDX Tabular Data Endpoints: Jupyter Notebook\n",
    "\n",
    "This notebook shows how to query the HDX Tabular Data endpoints from Python using both native (`datastore_search`) and SQL (`datastore_search_sql`) with filters and joins along with investigating the schema through the `datastore_info` endpoint. It also includes an advanced section on how to use the HDX metadata endpoints to search for datasets.\n",
    "\n",
    "**Please note:**  \n",
    "- Use your own API token. Do not commit or share it. Treat it like a password and keep it safe.\n",
    "- If using Google Colab, you can set your token at runtime in a cell. Do not save it to Drive or source control.  \n",
    "- Replace placeholder values like `\"RESOURCE_ID\"` with real ones.\n",
    "- Use the [documentation](https://un-ocha-centre-for-humanitarian.gitbook.io/hdx-docs/build-with-hdx/build-with-hdx/hdx-api/tabular-data-endpoints) to answer any other questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c724ce",
   "metadata": {
    "id": "d4c724ce"
   },
   "source": [
    "\n",
    "## 1. Set your API token\n",
    "\n",
    "Set your API token by saving it as an environment variable (`API_TOKEN`). See instructions on how to generate your token in the [documentation](https://un-ocha-centre-for-humanitarian.gitbook.io/hdx-docs/build-with-hdx/build-with-hdx/overview/hdx-core-concepts). In the notebook, load it with a config file or create a secret in notebook editors like Google Collab. Do not hardcode or commit your token in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33022d9f",
   "metadata": {
    "id": "33022d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDX API_TOKEN loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Retrieve the HDX API token from environment variables\n",
    "API_TOKEN = os.getenv(\"HDX_API_TOKEN\")\n",
    "\n",
    "# Check that the token exists\n",
    "if not API_TOKEN:\n",
    "    raise ValueError(\"HDX_API_TOKEN not found in environment variables\")\n",
    "\n",
    "print(\"HDX API_TOKEN loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec7a24",
   "metadata": {
    "id": "c7ec7a24"
   },
   "source": [
    "## 2. Set variables: Base URL, resource IDs, and headers\n",
    "You will need to set the base for the API endpoints and `resource_id` of the datastore active HDX resources. This can be found via the UI, exact instructions in the [documentation](https://un-ocha-centre-for-humanitarian.gitbook.io/hdx-docs/build-with-hdx/build-with-hdx/hdx-api/tabular-data-endpoints/available-data-and-resource-ids). (See advanced section below on how to query the HDX metadata endpoints for `resource_id` as well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc0d9d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcc0d9d5",
    "outputId": "50b2091a-ed91-4f97-a20f-c13f9ac130a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using resources: 45036735-305b-42ae-9aef-b941d6dcb6d6 and 0e6fe8ce-f7c5-4320-bc57-bc95ed7fcd7b\n"
     ]
    }
   ],
   "source": [
    "BASE = \"https://data.humdata.org/api/action\"\n",
    "HNO_RESOURCE_ID = \"45036735-305b-42ae-9aef-b941d6dcb6d6\" # Replace with your resource id, this is for affected people\n",
    "RAINFALL_RESOURCE_ID = \"0e6fe8ce-f7c5-4320-bc57-bc95ed7fcd7b\"  # Replace with your resource id, this is for rainfall\n",
    "HEADERS = {\"Authorization\": API_TOKEN} if API_TOKEN else {}\n",
    "print(\"Using resources:\", HNO_RESOURCE_ID, \"and\", RAINFALL_RESOURCE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04a32f",
   "metadata": {
    "id": "cf04a32f"
   },
   "source": [
    "## 3. Load packages and helper functions\n",
    "Load the required packages and basic backoff, native calls, SQL calls, and paginated fetch helpers. You may not use all of these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fae6602",
   "metadata": {
    "id": "7fae6602"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# GET with basic exponential backoff and JSON response\n",
    "def get_with_backoff(url, headers=None, tries=5, timeout=60):\n",
    "    for i in range(tries):\n",
    "        r = requests.get(url, headers=headers or {}, timeout=timeout)\n",
    "        if r.status_code in (429, 500, 502, 503, 504):\n",
    "            # back off and try again\n",
    "            time.sleep(2 ** i)\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "    raise RuntimeError(f\"Request failed after {tries} tries: {url}\")\n",
    "\n",
    "# Search datastore with pagination limit of 32,000\n",
    "def datastore_search(resource_id, limit=32000, offset=0, filters=None, fields=None):\n",
    "    params = {\n",
    "        \"resource_id\": resource_id,\n",
    "        \"limit\": str(limit),\n",
    "        \"offset\": str(offset),\n",
    "    }\n",
    "    if filters:\n",
    "        params[\"filters\"] = json.dumps(filters)\n",
    "    if fields:\n",
    "        params[\"fields\"] = \",\".join(fields)\n",
    "    url = f\"{BASE}/datastore_search?{urllib.parse.urlencode(params)}\"\n",
    "    return get_with_backoff(url, headers=HEADERS)\n",
    "\n",
    "# Native fetch with pagination using limit and offset\n",
    "def fetch_all_native(resource_id, page_size=32000, filters=None, fields=None):\n",
    "    out = []\n",
    "    offset = 0\n",
    "    total = None\n",
    "    while True:\n",
    "        resp = datastore_search(resource_id, limit=page_size, offset=offset, filters=filters, fields=fields)\n",
    "        if not resp.get(\"success\"):\n",
    "            raise RuntimeError(f\"API indicated failure: {resp}\")\n",
    "        result = resp[\"result\"]\n",
    "        if total is None:\n",
    "            total = result.get(\"total\", 0)\n",
    "        rows = result.get(\"records\", [])\n",
    "        if not rows:\n",
    "            break\n",
    "        out.extend(rows)\n",
    "        offset += len(rows)\n",
    "        if offset >= total:\n",
    "            break\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# SQL search\n",
    "def datastore_search_sql(sql):\n",
    "    q = {\"sql\": sql}\n",
    "    url = f\"{BASE}/datastore_search_sql?{urllib.parse.urlencode(q)}\"\n",
    "    return get_with_backoff(url, headers=HEADERS)\n",
    "\n",
    "# Iterate using SQL with stable ORDER BY and OFFSET\n",
    "def fetch_all_sql(resource_id, order_by, page_size=32000, where=None, fields=\"*\"):\n",
    "    all_rows = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        sql = f'SELECT {fields} FROM \"{resource_id}\"'\n",
    "        if where:\n",
    "            sql += f\" WHERE {where}\"\n",
    "        sql += f' ORDER BY \"{order_by}\" LIMIT {page_size} OFFSET {offset}'\n",
    "\n",
    "        data = datastore_search_sql(sql)\n",
    "        rows = data.get(\"result\", {}).get(\"records\", [])\n",
    "        if not rows:\n",
    "            break\n",
    "\n",
    "        all_rows.extend(rows)\n",
    "        offset += len(rows)\n",
    "        if len(rows) < page_size:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame.from_records(all_rows) if all_rows else pd.DataFrame()\n",
    "\n",
    "# Show schema, field types, and index info\n",
    "def show_schema(resource_id, label):\n",
    "    url = f\"{BASE}/datastore_info?{urllib.parse.urlencode({'id': resource_id})}\"\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    if not data.get(\"success\"):\n",
    "        raise RuntimeError(f\"Probe failed: {data}\")\n",
    "\n",
    "    result = data.get(\"result\", {}) or {}\n",
    "    fields = result.get(\"fields\", []) or []\n",
    "    primary_key = set(result.get(\"primary_key\", []) or [])\n",
    "    indexes = result.get(\"indexes\", []) or []\n",
    "    \n",
    "    indexed_cols = set()\n",
    "    for idx in indexes:\n",
    "        if isinstance(idx, (list, tuple)):\n",
    "            indexed_cols.update(idx)\n",
    "        elif isinstance(idx, str):\n",
    "            indexed_cols.add(idx)\n",
    "\n",
    "    print(f\"{label} schema ({len(fields)} fields):\")\n",
    "    for f in fields:\n",
    "        fid = f.get(\"id\")\n",
    "        ftype = f.get(\"type\")\n",
    "        is_index = (fid in primary_key) or (fid in indexed_cols)\n",
    "        print(f\"  {fid}: {ftype} | is_index={bool(is_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49614c5-519b-4056-b5ee-2067f91d0644",
   "metadata": {},
   "source": [
    "## 4. Advanced: Search with the HDX CKAN API for datastore resources\n",
    "This is an advanced and optional section showing you how to find `datastore_active` resources within the CKAN API, a separate HDX API endpoint. This is useful for browsing the data catalogue and searching for the data you want. The `resource_id` is what is then used in the datastore API call (native and SQL).\n",
    "\n",
    "The `resource_id` can also be found in the UI directly as in the earlier example. See more information in the [documentation](https://un-ocha-centre-for-humanitarian.gitbook.io/hdx-docs/build-with-hdx/build-with-hdx/overview/hdx-core-concepts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b763a3-c149-42de-ac8d-3a7687ed5b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matching datasets: 1\n",
      "2 Tabular API active WFP resources found containing 'rainfall' and groups: afg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>organization</th>\n",
       "      <th>resource_name</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afg-rainfall-subnational</td>\n",
       "      <td>Afghanistan: Rainfall Indicators at Subnationa...</td>\n",
       "      <td>wfp</td>\n",
       "      <td>afg-rainfall-subnat-full.csv</td>\n",
       "      <td>0e6fe8ce-f7c5-4320-bc57-bc95ed7fcd7b</td>\n",
       "      <td>https://data.humdata.org/dataset/3b5e8a5c-e4e0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afg-rainfall-subnational</td>\n",
       "      <td>Afghanistan: Rainfall Indicators at Subnationa...</td>\n",
       "      <td>wfp</td>\n",
       "      <td>afg-rainfall-subnat-5ytd.csv</td>\n",
       "      <td>e6c0b120-6e2e-43f2-bf18-ef51f5fa9c20</td>\n",
       "      <td>https://data.humdata.org/dataset/3b5e8a5c-e4e0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset_name  \\\n",
       "0  afg-rainfall-subnational   \n",
       "1  afg-rainfall-subnational   \n",
       "\n",
       "                                       dataset_title organization  \\\n",
       "0  Afghanistan: Rainfall Indicators at Subnationa...          wfp   \n",
       "1  Afghanistan: Rainfall Indicators at Subnationa...          wfp   \n",
       "\n",
       "                  resource_name                           resource_id  \\\n",
       "0  afg-rainfall-subnat-full.csv  0e6fe8ce-f7c5-4320-bc57-bc95ed7fcd7b   \n",
       "1  afg-rainfall-subnat-5ytd.csv  e6c0b120-6e2e-43f2-bf18-ef51f5fa9c20   \n",
       "\n",
       "                                                 url  \n",
       "0  https://data.humdata.org/dataset/3b5e8a5c-e4e0...  \n",
       "1  https://data.humdata.org/dataset/3b5e8a5c-e4e0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search CKAN for datasets where title includes \"rainfall\", country (group) is AFG, and organization is WFP\n",
    "params = {\n",
    "    \"q\": 'title:rainfall',\n",
    "    \"fq\": 'organization:wfp +groups:afg',\n",
    "    \"rows\": 1000\n",
    "}\n",
    "\n",
    "resp = requests.get(f\"{BASE}/package_search\", params=params, headers=HEADERS)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()[\"result\"]\n",
    "print(\"Total matching datasets:\", data[\"count\"])\n",
    "datasets = data[\"results\"]\n",
    "\n",
    "rows = []\n",
    "for ds in datasets:\n",
    "    for res in ds.get(\"resources\", []):\n",
    "        if res.get(\"datastore_active\"):\n",
    "            rows.append({\n",
    "                \"dataset_name\": ds.get(\"name\"),\n",
    "                \"dataset_title\": ds.get(\"title\"),\n",
    "                \"organization\": (ds.get(\"organization\") or {}).get(\"name\"),\n",
    "                \"resource_name\": res.get(\"name\"),\n",
    "                \"resource_id\": res.get(\"id\"),\n",
    "                \"url\": res.get(\"url\")\n",
    "            })\n",
    "\n",
    "ckan_search_df = pd.DataFrame(rows)\n",
    "print(f\"{len(ckan_search_df)} Tabular API active WFP resources found containing 'rainfall' and groups: afg\")\n",
    "display(ckan_search_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d3db7",
   "metadata": {
    "id": "d70d3db7"
   },
   "source": [
    "\n",
    "## 5. Minimal probe\n",
    "Confirm access and the presence of rows using a small native HDX Datastore API call. This will simply confirm that you are able to access the API with your API token and `resource_id`.\n",
    "\n",
    "*Refer to the [documentation](https://un-ocha-centre-for-humanitarian.gitbook.io/hdx-docs/build-with-hdx/build-with-hdx/hdx-api/tabular-data-endpoints/troubleshooting-and-error-handling) with troubleshooting if you are unable to access with this minimal probe.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3f9f4-519f-47d4-85f2-7672e838e6ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7758f78f",
    "outputId": "b574bb1d-4976-4ce4-f8b8-0f677dffa415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe success: True\n",
      "Total rows in table: 700161\n",
      "Example record:\n",
      "{'_id': 1, 'date': '1981-01-01T00:00:00', 'adm_level': 1, 'adm_id': 900486, 'PCODE': 'AF21', 'n_pixels': 675.0, 'rfh': 11.9792595, 'rfh_avg': 12.415753, 'r1h': None, 'r1h_avg': None, 'r3h': None, 'r3h_avg': None, 'rfq': 97.49369, 'r1q': None, 'r3q': None, 'version': 'final'}\n"
     ]
    }
   ],
   "source": [
    "# Minimal probe to confirm datastore access\n",
    "try:\n",
    "    probe = datastore_search(RAINFALL_RESOURCE_ID, limit=1)\n",
    "    if not probe.get(\"success\"):\n",
    "        raise RuntimeError(f\"Probe failed: {probe}\")\n",
    "\n",
    "    result = probe.get(\"result\", {})\n",
    "    total = result.get(\"total\")\n",
    "    records = result.get(\"records\", [])\n",
    "\n",
    "    print(\"Probe success:\", probe.get(\"success\"))\n",
    "    print(\"Total rows in table:\", total)\n",
    "    if records:\n",
    "        print(\"Example record:\")\n",
    "        print(records[0])\n",
    "    else:\n",
    "        print(\"No rows returned. Try removing filters or checking the resource_id.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Probe request failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980dc660-e7ab-4299-9c4d-6cc2a2001d7f",
   "metadata": {},
   "source": [
    "## 6. Information call to see data schema\n",
    "A simple API call using the `datastore_info` endpoint of the `resource_id` you are calling. This helps us understand the data schema of the resource for use in filtering and joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8aa78e-1bd1-4e8d-9860-df7df4f4987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rainfall schema (15 fields):\n",
      "  date: timestamp | is_index=False\n",
      "  adm_level: numeric | is_index=False\n",
      "  adm_id: numeric | is_index=False\n",
      "  PCODE: text | is_index=False\n",
      "  n_pixels: numeric | is_index=False\n",
      "  rfh: numeric | is_index=False\n",
      "  rfh_avg: numeric | is_index=False\n",
      "  r1h: numeric | is_index=False\n",
      "  r1h_avg: numeric | is_index=False\n",
      "  r3h: numeric | is_index=False\n",
      "  r3h_avg: numeric | is_index=False\n",
      "  rfq: numeric | is_index=False\n",
      "  r1q: numeric | is_index=False\n",
      "  r3q: numeric | is_index=False\n",
      "  version: text | is_index=False\n"
     ]
    }
   ],
   "source": [
    "# Confirm datastore_info access and show schema\n",
    "try:\n",
    "    show_schema(RAINFALL_RESOURCE_ID, \"Rainfall\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Probe request failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce79802",
   "metadata": {
    "id": "6ce79802"
   },
   "source": [
    "## 7. Native fetch with filters and pagination\n",
    "Now we can adjust `filters` and `fields` to match the schema of the `resource_id` you are calling. This is just a simple example which can be edited with your desired filters based on the data resource schema and data types that you are calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754cec36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "754cec36",
    "outputId": "d43aa40b-e0ac-40a6-f7a8-f4fb36381bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native fetch returned 1617 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>date</th>\n",
       "      <th>adm_level</th>\n",
       "      <th>adm_id</th>\n",
       "      <th>PCODE</th>\n",
       "      <th>n_pixels</th>\n",
       "      <th>rfh</th>\n",
       "      <th>rfh_avg</th>\n",
       "      <th>r1h</th>\n",
       "      <th>r1h_avg</th>\n",
       "      <th>r3h</th>\n",
       "      <th>r3h_avg</th>\n",
       "      <th>rfq</th>\n",
       "      <th>r1q</th>\n",
       "      <th>r3q</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32341</td>\n",
       "      <td>1981-01-01T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>10.568534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.490540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32342</td>\n",
       "      <td>1981-01-11T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>6.319328</td>\n",
       "      <td>9.605509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.500404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32343</td>\n",
       "      <td>1981-01-21T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>17.761906</td>\n",
       "      <td>13.974603</td>\n",
       "      <td>30.366947</td>\n",
       "      <td>34.148647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.959854</td>\n",
       "      <td>90.34015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32344</td>\n",
       "      <td>1981-02-01T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>15.184874</td>\n",
       "      <td>27.983007</td>\n",
       "      <td>39.266106</td>\n",
       "      <td>51.563118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.197792</td>\n",
       "      <td>78.25967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32345</td>\n",
       "      <td>1981-02-11T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>34.843136</td>\n",
       "      <td>22.349020</td>\n",
       "      <td>67.789920</td>\n",
       "      <td>64.306630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.683960</td>\n",
       "      <td>105.02590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                 date  adm_level  adm_id PCODE  n_pixels        rfh  \\\n",
       "0  32341  1981-01-01T00:00:00          1  900506  AF16     357.0   6.285714   \n",
       "1  32342  1981-01-11T00:00:00          1  900506  AF16     357.0   6.319328   \n",
       "2  32343  1981-01-21T00:00:00          1  900506  AF16     357.0  17.761906   \n",
       "3  32344  1981-02-01T00:00:00          1  900506  AF16     357.0  15.184874   \n",
       "4  32345  1981-02-11T00:00:00          1  900506  AF16     357.0  34.843136   \n",
       "\n",
       "     rfh_avg        r1h    r1h_avg  r3h  r3h_avg         rfq        r1q  r3q  \\\n",
       "0  10.568534        NaN        NaN  NaN      NaN   72.490540        NaN  NaN   \n",
       "1   9.605509        NaN        NaN  NaN      NaN   77.500404        NaN  NaN   \n",
       "2  13.974603  30.366947  34.148647  NaN      NaN  119.959854   90.34015  NaN   \n",
       "3  27.983007  39.266106  51.563118  NaN      NaN   61.197792   78.25967  NaN   \n",
       "4  22.349020  67.789920  64.306630  NaN      NaN  145.683960  105.02590  NaN   \n",
       "\n",
       "  version  \n",
       "0   final  \n",
       "1   final  \n",
       "2   final  \n",
       "3   final  \n",
       "4   final  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: native fetch with filters and pagination\n",
    "filters = {\n",
    "    \"PCODE\": \"AF16\" # Replace with a valid column:value in your dataset\n",
    "}\n",
    "\n",
    "fields = None\n",
    "\n",
    "try:\n",
    "    df_native = fetch_all_native(\n",
    "        RAINFALL_RESOURCE_ID,\n",
    "        page_size=32000,\n",
    "        filters=filters,\n",
    "        fields=fields\n",
    "    )\n",
    "\n",
    "    n_rows = len(df_native)\n",
    "    print(f\"Native fetch returned {n_rows} rows\")\n",
    "    if n_rows == 0:\n",
    "        print(\"No rows matched the filter. Try adjusting filters or check column names/types.\")\n",
    "    else:\n",
    "        display(df_native.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Native fetch failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59decac8",
   "metadata": {
    "id": "59decac8"
   },
   "source": [
    "\n",
    "## 8. SQL fetch with stable ordering\n",
    "Here is a SQL example with a deterministic column for `ORDER BY` which can be used with a primary key like `\"date\"` or `\"id\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f5485a-8655-4041-a799-920b7c28c93e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "769e09a3",
    "outputId": "722635c3-e09a-4d9f-9cb1-91a7d875b5fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL fetch returned 1617 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_full_text</th>\n",
       "      <th>date</th>\n",
       "      <th>adm_level</th>\n",
       "      <th>adm_id</th>\n",
       "      <th>PCODE</th>\n",
       "      <th>n_pixels</th>\n",
       "      <th>rfh</th>\n",
       "      <th>rfh_avg</th>\n",
       "      <th>r1h</th>\n",
       "      <th>r1h_avg</th>\n",
       "      <th>r3h</th>\n",
       "      <th>r3h_avg</th>\n",
       "      <th>rfq</th>\n",
       "      <th>r1q</th>\n",
       "      <th>r3q</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32341</td>\n",
       "      <td>'-01':2,3 '00':5,6 '1':7 '10.568534':12 '1981'...</td>\n",
       "      <td>1981-01-01T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>10.568534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.490540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32342</td>\n",
       "      <td>'-01':2 '-11':3 '00':5,6 '1':7 '1981':1 '357.0...</td>\n",
       "      <td>1981-01-11T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>6.319328</td>\n",
       "      <td>9.605509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.500404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32343</td>\n",
       "      <td>'-01':2 '-21':3 '00':5,6 '1':7 '119.959854':15...</td>\n",
       "      <td>1981-01-21T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>17.761906</td>\n",
       "      <td>13.974603</td>\n",
       "      <td>30.366947</td>\n",
       "      <td>34.148647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.959854</td>\n",
       "      <td>90.34015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32344</td>\n",
       "      <td>'-01':3 '-02':2 '00':5,6 '1':7 '15.184874':11 ...</td>\n",
       "      <td>1981-02-01T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>15.184874</td>\n",
       "      <td>27.983007</td>\n",
       "      <td>39.266106</td>\n",
       "      <td>51.563118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.197792</td>\n",
       "      <td>78.25967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32345</td>\n",
       "      <td>'-02':2 '-11':3 '00':5,6 '1':7 '105.0259':16 '...</td>\n",
       "      <td>1981-02-11T00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>900506</td>\n",
       "      <td>AF16</td>\n",
       "      <td>357.0</td>\n",
       "      <td>34.843136</td>\n",
       "      <td>22.349020</td>\n",
       "      <td>67.789920</td>\n",
       "      <td>64.306630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.683960</td>\n",
       "      <td>105.02590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                                         _full_text  \\\n",
       "0  32341  '-01':2,3 '00':5,6 '1':7 '10.568534':12 '1981'...   \n",
       "1  32342  '-01':2 '-11':3 '00':5,6 '1':7 '1981':1 '357.0...   \n",
       "2  32343  '-01':2 '-21':3 '00':5,6 '1':7 '119.959854':15...   \n",
       "3  32344  '-01':3 '-02':2 '00':5,6 '1':7 '15.184874':11 ...   \n",
       "4  32345  '-02':2 '-11':3 '00':5,6 '1':7 '105.0259':16 '...   \n",
       "\n",
       "                  date  adm_level  adm_id PCODE  n_pixels        rfh  \\\n",
       "0  1981-01-01T00:00:00          1  900506  AF16     357.0   6.285714   \n",
       "1  1981-01-11T00:00:00          1  900506  AF16     357.0   6.319328   \n",
       "2  1981-01-21T00:00:00          1  900506  AF16     357.0  17.761906   \n",
       "3  1981-02-01T00:00:00          1  900506  AF16     357.0  15.184874   \n",
       "4  1981-02-11T00:00:00          1  900506  AF16     357.0  34.843136   \n",
       "\n",
       "     rfh_avg        r1h    r1h_avg  r3h  r3h_avg         rfq        r1q  r3q  \\\n",
       "0  10.568534        NaN        NaN  NaN      NaN   72.490540        NaN  NaN   \n",
       "1   9.605509        NaN        NaN  NaN      NaN   77.500404        NaN  NaN   \n",
       "2  13.974603  30.366947  34.148647  NaN      NaN  119.959854   90.34015  NaN   \n",
       "3  27.983007  39.266106  51.563118  NaN      NaN   61.197792   78.25967  NaN   \n",
       "4  22.349020  67.789920  64.306630  NaN      NaN  145.683960  105.02590  NaN   \n",
       "\n",
       "  version  \n",
       "0   final  \n",
       "1   final  \n",
       "2   final  \n",
       "3   final  \n",
       "4   final  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: SQL fetch with stable ordering and pagination\n",
    "sql_where = \"\\\"PCODE\\\" = 'AF16'\"\n",
    "\n",
    "try:\n",
    "    df_sql = fetch_all_sql(\n",
    "        RAINFALL_RESOURCE_ID,\n",
    "        order_by=\"_id\",\n",
    "        page_size=32000,\n",
    "        where=sql_where,\n",
    "        fields=\"*\"\n",
    "    )\n",
    "\n",
    "    print(f\"SQL fetch returned {len(df_sql)} rows\")\n",
    "    display(df_sql.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"SQL fetch failed:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "793f5656-f63c-4ce2-9b25-87cc4b0b8fa9",
   "metadata": {},
   "source": [
    "## 9. Advanced: SQL joins\n",
    "Here we inspect the schemas of two HDX Datastore resources (WFP rainfall and Humanitarian Needs Assessment) to identify their available fields, then build and run an SQL query that joins the two datasets for Afghanistan by matching their locations, producing a combined DataFrame with rainfall and affected people in the Food Security sector. This allows us to fetch data from two resources at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8e325e-c281-49b9-b316-c1ee96a76213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First (Rainfall) schema (15 fields):\n",
      "  date: timestamp | is_index=False\n",
      "  adm_level: numeric | is_index=False\n",
      "  adm_id: numeric | is_index=False\n",
      "  PCODE: text | is_index=False\n",
      "  n_pixels: numeric | is_index=False\n",
      "  rfh: numeric | is_index=False\n",
      "  rfh_avg: numeric | is_index=False\n",
      "  r1h: numeric | is_index=False\n",
      "  r1h_avg: numeric | is_index=False\n",
      "  r3h: numeric | is_index=False\n",
      "  r3h_avg: numeric | is_index=False\n",
      "  rfq: numeric | is_index=False\n",
      "  r1q: numeric | is_index=False\n",
      "  r3q: numeric | is_index=False\n",
      "  version: text | is_index=False\n",
      "Second (Affected People) schema (21 fields):\n",
      "  location_code: text | is_index=False\n",
      "  has_hrp: text | is_index=False\n",
      "  in_gho: text | is_index=False\n",
      "  provider_admin1_name: text | is_index=False\n",
      "  provider_admin2_name: text | is_index=False\n",
      "  admin1_code: text | is_index=False\n",
      "  admin1_name: text | is_index=False\n",
      "  admin2_code: text | is_index=False\n",
      "  admin2_name: text | is_index=False\n",
      "  admin_level: numeric | is_index=False\n",
      "  sector_code: text | is_index=False\n",
      "  sector_name: text | is_index=False\n",
      "  category: text | is_index=False\n",
      "  population_status: text | is_index=False\n",
      "  population: numeric | is_index=False\n",
      "  reference_period_start: timestamp | is_index=False\n",
      "  reference_period_end: timestamp | is_index=False\n",
      "  dataset_hdx_id: text | is_index=False\n",
      "  resource_hdx_id: text | is_index=False\n",
      "  warning: text | is_index=False\n",
      "  error: text | is_index=False\n"
     ]
    }
   ],
   "source": [
    "show_schema(RAINFALL_RESOURCE_ID, \"First (Rainfall)\")\n",
    "show_schema(HNO_RESOURCE_ID, \"Second (Affected People)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9e9206-1ce1-45b9-9628-411647735aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined rows for AFG in 2025: 398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin1_code</th>\n",
       "      <th>admin2_code</th>\n",
       "      <th>admin1_name</th>\n",
       "      <th>admin2_name</th>\n",
       "      <th>year</th>\n",
       "      <th>affected_population</th>\n",
       "      <th>avg_rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF01</td>\n",
       "      <td>AF0101</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>2025</td>\n",
       "      <td>1285085</td>\n",
       "      <td>8.789394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF01</td>\n",
       "      <td>AF0102</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>Paghman</td>\n",
       "      <td>2025</td>\n",
       "      <td>73730</td>\n",
       "      <td>11.269408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF01</td>\n",
       "      <td>AF0103</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>Chahar Asyab</td>\n",
       "      <td>2025</td>\n",
       "      <td>21374</td>\n",
       "      <td>9.074916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF01</td>\n",
       "      <td>AF0104</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>Bagrami</td>\n",
       "      <td>2025</td>\n",
       "      <td>156742</td>\n",
       "      <td>8.786410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF01</td>\n",
       "      <td>AF0105</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>Deh Sabz</td>\n",
       "      <td>2025</td>\n",
       "      <td>49294</td>\n",
       "      <td>9.028668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  admin1_code admin2_code admin1_name   admin2_name  year  \\\n",
       "0        AF01      AF0101       Kabul         Kabul  2025   \n",
       "1        AF01      AF0102       Kabul       Paghman  2025   \n",
       "2        AF01      AF0103       Kabul  Chahar Asyab  2025   \n",
       "3        AF01      AF0104       Kabul       Bagrami  2025   \n",
       "4        AF01      AF0105       Kabul      Deh Sabz  2025   \n",
       "\n",
       "   affected_population  avg_rainfall  \n",
       "0              1285085      8.789394  \n",
       "1                73730     11.269408  \n",
       "2                21374      9.074916  \n",
       "3               156742      8.786410  \n",
       "4                49294      9.028668  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL join HNO and rainfall for Afghanistan 2025\n",
    "# One row per admin1_code per year with food security affected people and average rainfall\n",
    "sql = f\"\"\"\n",
    "WITH rain AS (\n",
    "  SELECT\n",
    "    \"PCODE\" AS admin2_code,\n",
    "    TO_CHAR(date, 'YYYY')  AS year,\n",
    "    AVG(rfh_avg) AS avg_rainfall\n",
    "  FROM \"{RAINFALL_RESOURCE_ID}\"\n",
    "  WHERE TO_CHAR(date, 'YYYY') = '2025'\n",
    "  GROUP BY \"PCODE\", year\n",
    "),\n",
    "\n",
    "hno AS (\n",
    "  SELECT\n",
    "    admin1_code,\n",
    "    admin2_code,\n",
    "    admin1_name,\n",
    "    admin2_name,\n",
    "    TO_CHAR(reference_period_end, 'YYYY') AS year,\n",
    "    population\n",
    "  FROM \"{HNO_RESOURCE_ID}\"\n",
    "  WHERE location_code      = 'AFG'\n",
    "    AND sector_name        = 'Food Security'\n",
    "    AND population_status  = 'INN'\n",
    "    AND lower(category)    = 'total'\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  h.admin1_code,\n",
    "  h.admin2_code,\n",
    "  h.admin1_name,\n",
    "  h.admin2_name,\n",
    "  h.year,\n",
    "  h.population       AS affected_population,\n",
    "  r.avg_rainfall\n",
    "FROM hno h\n",
    "JOIN rain r\n",
    "  ON h.admin2_code = r.admin2_code\n",
    " AND h.year       = r.year\n",
    "ORDER BY h.admin1_code, h.admin2_code\n",
    "\"\"\"\n",
    "\n",
    "sql_data = datastore_search_sql(sql)\n",
    "df_joined = pd.DataFrame(sql_data.get(\"result\", {}).get(\"records\", []))\n",
    "\n",
    "print(f\"Joined rows for AFG in 2025: {len(df_joined)}\")\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365b070",
   "metadata": {
    "id": "a365b070"
   },
   "source": [
    "\n",
    "## 10. Troubleshooting quick checks\n",
    "\n",
    "Here are some quick sanity checks to help troubleshoot. If you see empty results or errors:\n",
    "1. Verify your `\"resource_id\"` is correct and the resource has HDX Tabular Data endpoints access enabled.\n",
    "2. Confirm the `\"API_TOKEN\"` is set in this session and is correct for your account.\n",
    "3. Remove filters and try `limit=1` again.  \n",
    "4. For SQL, ensure the table name is quoted `\"resource_id\"` and the query is URL-encoded by the helper.  \n",
    "5. Slow or intermittent errors can be rate limiting. Re-run cells after a short pause and add throttling.\n",
    "   \n",
    "*For all other questions, please refer to our [documentation](https://un-ocha-centre-for-humanitarian.gitbook.io/hdx-docs/build-with-hdx/build-with-hdx/hdx-api/tabular-data-endpoints).*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:hdx]",
   "language": "python",
   "name": "conda-env-hdx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
